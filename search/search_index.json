{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Study Notes Blog # The aim of this blog is to document all the notes, exercises and research in Data Science At the moment, this blog has statistics notes along with the exercises. In case you find any errors, please let me know in the respective comments section. Topic Notes Link Exercises Link Statistics Statistics Notes Statistics Exercises","title":"Home"},{"location":"#study_notes_blog","text":"The aim of this blog is to document all the notes, exercises and research in Data Science At the moment, this blog has statistics notes along with the exercises. In case you find any errors, please let me know in the respective comments section. Topic Notes Link Exercises Link Statistics Statistics Notes Statistics Exercises","title":"Study Notes Blog"},{"location":"exercises/","text":"List of exercises and the solutions # Statistics Exercises # Course Class Exercise Number + Link Exercise Description Statistics 01 Exercise01 Statistics 01 Exercise02 Statistics 02 Exercise03 Statistics 02 Exercise04 Statistics 03 Exercise05 Normal Distribution Vs Probability Distribution Statistics 03 Exercise06 Confidence Interval","title":"Index"},{"location":"exercises/#list_of_exercises_and_the_solutions","text":"","title":"List of exercises and the solutions"},{"location":"exercises/#statistics_exercises","text":"Course Class Exercise Number + Link Exercise Description Statistics 01 Exercise01 Statistics 01 Exercise02 Statistics 02 Exercise03 Statistics 02 Exercise04 Statistics 03 Exercise05 Normal Distribution Vs Probability Distribution Statistics 03 Exercise06 Confidence Interval","title":"Statistics Exercises"},{"location":"exercises/exercise05/","text":"Normal Distribution is a probability distribution. # The topic in question is - Is normal distribution a probability distribution? Yes, it is and this writeup provides justification as to why it is so! Revisiting the Normal distribution # Let's revisit the normal distribution once - its characteristics and emprical rule Normal distribution is the distribution of data that is symmetric over the mean. 50% of the data lie to the left and 50% of the data lie to the right At the origin, mean = median = mode = 0 Emprical rule # The emprical rule states that - 68% of the data will be within one standard deviation of the mean - 95% of the data will be within two standard deviations from the mean - 99.7% of the data will be within three standard deviations from the mean Lets see that in the figure below Example Dataset # Let's plot a normal distribution graph of 300 people with a mean salary of 50,000 and standard deviation of 8700 (sigma) Descriptive Statistics Value Mean 50000 Median 50000 Std dev p 8700 Mode 50000 Then the following will be the ranges of the salary from the mean. Sigma Range Salary -1 sigma 41300 +1 sigma 58700 -2 sigma 32600 +2 sigma 67400 -3 sigma 23900 +3 sigma 76100 The number of people with the respective salary range and the normal distribution is mentioned below. Salary Range No of people Norm Dist 23000-33000 0 0 33001-41000 64 0.00118224 41001-50000 88 0.003468298 50001-59000 87 0.003404399 59001-67000 63 0.001154427 67001-76000 0 0 Normal distribution computed with NORMAL.DIST function in EXCEL So, we have all of our 300 people salaries mapped as a normal distribution. Random sample # Let's take a random sample from our range of salaries. NOTE: use the EXCEL RANDBETWEEN function to generate a random sample provided a range. Here our range is from -3 sigma to +3 sigma which is from 23900 to 76100 The random sample i.e. salary taken is 47243 Question? # What is the chance that this random sample (e.g. 47243 ) falls within -3 sigma to +3 sigma? i.e. the area under the curve (highlighted in red color)? Can we say that 99.7% of the time of the time the random sample taken will fall within the -3 sigma to +3 sigma (i.e. the area under the curve) This 99.7% chance is called as the probability of the sample falling within the range -3 sigma to +3 sigma. The range of Probability is from 0 to 1 . i.e 0 for no chance and 1 for 100% chance. One more sample # Let's take one more sample between -3 sigma and +3 sigma. What is the chance that it will fall under the area of the curve highlighted below (in red color) i.e. from -1 sigma to +1 sigma? Can we say that it will be 68% or 0.68 probability? Lets prove it! The area under the chart is from -1 sigma to +1 sigma. Correct? Let's revisit Z (zee) scores once z scores is the number of units of standard deviation from the mean. Here the range in consideration is -1 sigma to +1 sigma i.e we want to find out if a random sample (salary) falls within this range. So the z scores are -1 and +1 . To be precise we can say -1.0 and +1.0 Let's bring Z-Tables. Z-Tables provides us the area under the curve / probability. Using Z-tables lets find the area under the curve of -1.0Z Since -1 is a negative Z, we see the negative Z score table and see that the probability is 0.15866 (see figure below) i.e if we take a random sample between -3 sigma and +3 sigma, the chance of the random sample falling under the area of the curve of -1Z is 15.866% . Thus Z tables us gives the probability. For +1Z , let's refer to the positive Z score table. The area under the curve is 0.84134 . (See fig below). To summarize, to find out the area under the curve -1Z to +1Z , we need to subtract the area under +1Z with -1Z Note: Zee is 1 unit of standard deviation. So it is -1 sigma to +1 sigma i.e 0.84134 - 0.15866 = 0.68268 . Thus 68.268% is the probability that a given random sample will fall under the range of -1 sigma to +1 sigma. In this way, we can find out the probability of a random variable falling under the area of the curve of the normal distribution for any Zee values. i.e from -3 sigma to -2 sigma. or from -2 sigma to +3 sigma etc. Conclusion # Thus we have emprically concluded that the normal distribution is a probability distribution as it helps to find the probability of a random variable falling within the normal distribution range.","title":"Exercise05"},{"location":"exercises/exercise05/#normal_distribution_is_a_probability_distribution","text":"The topic in question is - Is normal distribution a probability distribution? Yes, it is and this writeup provides justification as to why it is so!","title":"Normal Distribution is a probability distribution."},{"location":"exercises/exercise05/#revisiting_the_normal_distribution","text":"Let's revisit the normal distribution once - its characteristics and emprical rule Normal distribution is the distribution of data that is symmetric over the mean. 50% of the data lie to the left and 50% of the data lie to the right At the origin, mean = median = mode = 0","title":"Revisiting the Normal distribution"},{"location":"exercises/exercise05/#emprical_rule","text":"The emprical rule states that - 68% of the data will be within one standard deviation of the mean - 95% of the data will be within two standard deviations from the mean - 99.7% of the data will be within three standard deviations from the mean Lets see that in the figure below","title":"Emprical rule"},{"location":"exercises/exercise05/#example_dataset","text":"Let's plot a normal distribution graph of 300 people with a mean salary of 50,000 and standard deviation of 8700 (sigma) Descriptive Statistics Value Mean 50000 Median 50000 Std dev p 8700 Mode 50000 Then the following will be the ranges of the salary from the mean. Sigma Range Salary -1 sigma 41300 +1 sigma 58700 -2 sigma 32600 +2 sigma 67400 -3 sigma 23900 +3 sigma 76100 The number of people with the respective salary range and the normal distribution is mentioned below. Salary Range No of people Norm Dist 23000-33000 0 0 33001-41000 64 0.00118224 41001-50000 88 0.003468298 50001-59000 87 0.003404399 59001-67000 63 0.001154427 67001-76000 0 0 Normal distribution computed with NORMAL.DIST function in EXCEL So, we have all of our 300 people salaries mapped as a normal distribution.","title":"Example Dataset"},{"location":"exercises/exercise05/#random_sample","text":"Let's take a random sample from our range of salaries. NOTE: use the EXCEL RANDBETWEEN function to generate a random sample provided a range. Here our range is from -3 sigma to +3 sigma which is from 23900 to 76100 The random sample i.e. salary taken is 47243","title":"Random sample"},{"location":"exercises/exercise05/#question","text":"What is the chance that this random sample (e.g. 47243 ) falls within -3 sigma to +3 sigma? i.e. the area under the curve (highlighted in red color)? Can we say that 99.7% of the time of the time the random sample taken will fall within the -3 sigma to +3 sigma (i.e. the area under the curve) This 99.7% chance is called as the probability of the sample falling within the range -3 sigma to +3 sigma. The range of Probability is from 0 to 1 . i.e 0 for no chance and 1 for 100% chance.","title":"Question?"},{"location":"exercises/exercise05/#one_more_sample","text":"Let's take one more sample between -3 sigma and +3 sigma. What is the chance that it will fall under the area of the curve highlighted below (in red color) i.e. from -1 sigma to +1 sigma? Can we say that it will be 68% or 0.68 probability?","title":"One more sample"},{"location":"exercises/exercise05/#conclusion","text":"Thus we have emprically concluded that the normal distribution is a probability distribution as it helps to find the probability of a random variable falling within the normal distribution range.","title":"Conclusion"},{"location":"exercises/exercise06/","text":"date: Mar 08, 2020 Confidence level Vs the accuracy of estimation of the population mean # Does the more the confidence level in the confidence interval mean more the accurate prediction of the estimation of the population mean? Confidence Interval # A confidence interval is the range of numbers that is believed to include an unknown population parameter. Confidence Level # It is the measure of confidence that the unknown parameter (of the population) lies within the confidence interval. A case study # Comcast, the computer services company, is planning to invest heavily in online television service. As part of the decision, the company wants to estimate the average number of online shows a family of four would watch per day. A random sample of 100 families is obtained, and in this sample the average number of shows viewed per day is 6.5 and the population standard deviation is known to be 3.2 . Construct a 95% confidence interval for the average number of online television shows watched by the entire population of families of four. Known measures sample size - $$ n = 100 $$ sample mean - $$ \\bar{x} = 6.5 $$ population standard deviation - $$ \\sigma = 3.2 $$ confidence interval $$ Z = 1.96 (for the value of 95 percent) $$ To be found: Confidence interval of within which the population mean i.e. the average number of online television shows are watched by the entire population Let's picturize it Let's understand the picture Let's compute the confidence interval Confidence interval = \\mu \\pm Z * (\\sigma / \\sqrt n) \\mu \\pm Z * (\\sigma / \\sqrt n) Since we don't know the population parameter $$ \\mu $$ here, we will replace it with the value we know about the sample i.e. the sample mean $$ \\bar{x} $$ So the confidence interval in this case is $$ \\bar{x} \\pm Z * (\\sigma / \\sqrt n) $$ When substituted with values above, we get $$ confidence interval = 6.5 \\pm 1.96 * (3.2 / \\sqrt(100) $$ Note: The Z value for 95% confidence is 1.96 We get the confidence interval as [5.8728, 7.1272] If we reduce the confidence level to 80%, what happens? Note: the Z score for 80% confidence is 1.282 $$ confidence interval = 6.5 \\pm 1.28 * (3.2 / \\sqrt(100) $$ The confidence interval becomes [6.0904, 6.9096] Inference So, when the confidence level decreases from 95% to 80%, the confidence interval becomes narrorwer - which would mean our chance of finding the population mean reduces by 15% So it is better to always have a high confidence level to get more accurate estimations of the population mean What if i need to have a good confidence level i.e. 95% but the confidence interval should be narrower to get closer to the population mean - more accuracy in predicting? Answer Increase the sample size i.e. increase the sample size n=100 provided above to n=200 . The confidence interval becomes [6.0565, 6.9434]","title":"Exercise06"},{"location":"exercises/exercise06/#confidence_level_vs_the_accuracy_of_estimation_of_the_population_mean","text":"Does the more the confidence level in the confidence interval mean more the accurate prediction of the estimation of the population mean?","title":"Confidence level Vs the accuracy of estimation of the population mean"},{"location":"exercises/exercise06/#confidence_interval","text":"A confidence interval is the range of numbers that is believed to include an unknown population parameter.","title":"Confidence Interval"},{"location":"exercises/exercise06/#confidence_level","text":"It is the measure of confidence that the unknown parameter (of the population) lies within the confidence interval.","title":"Confidence Level"},{"location":"exercises/exercise06/#a_case_study","text":"Comcast, the computer services company, is planning to invest heavily in online television service. As part of the decision, the company wants to estimate the average number of online shows a family of four would watch per day. A random sample of 100 families is obtained, and in this sample the average number of shows viewed per day is 6.5 and the population standard deviation is known to be 3.2 . Construct a 95% confidence interval for the average number of online television shows watched by the entire population of families of four.","title":"A case study"},{"location":"statistics/","text":"Stats Home # The following topics are covered in statistics here Descriptive Statistics Inferential Statistics","title":"Stats Home"},{"location":"statistics/#stats_home","text":"The following topics are covered in statistics here Descriptive Statistics Inferential Statistics","title":"Stats Home"},{"location":"statistics/hypothesis_testing_01/","text":"Hypothesis Testing # What is Hypothesis Testing? # First let us understand what does the word hypothesis mean. Let us break the word into two parts hypo + thesis . What does thesis mean? thesis means something that has already been proven to be true. e.g Atleast 60% of the adult human body is made up of water. Sounds fine! So what does hypothesis mean? Hypothesis is something that is not yet been proven to be true. Let's come back to the original question! What is hypothesis testing? Can we say that it is the testing of hypothesis or more precisely the process of determining whether a given hypothesis is true or not To sum up, we take the hypothesis, we perform some statistical computations and prove if the hypothesis holds true or not. Null Hypothesis & Alternate Hypothesis # Null hypothesis is the assertion or belief that we hold as true unless we have sufficient evidence to prove otherwise. In statistical terms, we say it as the belief we hold about the value of a population parameter Remember Parameter is for the population and Statistic is for the sample Let's take an example and see what is the null hypothesis and how it is written. We believe that the mean of the population is 500 . Unless we obtain sufficient evidence that it is not 500 , our belief holds true i.e we accept that the mean is 500 So we can write it as null hypothesis: mean = 500 To write it more compactly, we can represent the same thing as \\mathbf{H}_\\mathbf{0} : \\mu = 500 \\mathbf{H}_\\mathbf{0} : \\mu = 500 where the symbol \\space\\mathbf{H}_\\mathbf{0} \\space\\mathbf{H}_\\mathbf{0} denotes Null hypothesis. The opposite of Null hypothesis is called as Alternate Hypothesis . That is, the negation of the null hypothesis. If there is a way to represent the null hypothesis, then there should be a way to represent the alternate hypothesis. Agreed? Ah, I see I have quoted a null hypothesis there! \\mathbf{H}_\\mathbf{1}: \\mu \\ne 500 \\mathbf{H}_\\mathbf{1}: \\mu \\ne 500 where the symbol \\space\\mathbf{H}_\\mathbf{1} \\space\\mathbf{H}_\\mathbf{1} denotes alternate hypothesis Note Since the null hypothesis and the alternate hypothesis are exactly opposite statements, only one can be true. Rejecting one is accepting the other. Let's check our understanding with a few examples Example 1 My broadband company claims that the minimum internet speed they are providing is 150 Mbps. However, I suspect that they are not providing the promised internet speed. Let's write the null and alternate hypothesis for this! \\mathbf{H}_\\mathbf{0}: speed \\ge 150 Mbps \\\\ \\mathbf{H}_\\mathbf{1}: speed < 150 Mbps \\mathbf{H}_\\mathbf{0}: speed \\ge 150 Mbps \\\\ \\mathbf{H}_\\mathbf{1}: speed < 150 Mbps Example 2 The project manager claims that the software defects raised are resolved within 5 business days. I being the quality department manager think it is taking longer to fix the bugs. Can we write the null and alternate hypothesis for this? \\mathbf{H}_\\mathbf{0}: Resolution\\space period \\le 5 days \\\\ \\mathbf{H}_\\mathbf{1}: Resolution\\space period > 5 days \\mathbf{H}_\\mathbf{0}: Resolution\\space period \\le 5 days \\\\ \\mathbf{H}_\\mathbf{1}: Resolution\\space period > 5 days Let's see how we can prove the alternate hypothesis Example 1 To check the internet speed, I visit Speed Test from my home computer and measure the speed. I do this 'n' number of times and find that the mean speed is around 100 Mbps. So we reject the null hypothesis and accept the alternate hypothesis - which is the internet speed is less than 150 Mbps Example 2 To verify the claims of the project manager, I take all of the 5 projects managed by him. He is relatively new to the project manager role and has only managed 5 projects so far. I get the bug details from the bug tracking system - bugzilla / jira for example. I compute the mean of all the bug resolution time by doing some computations ( calculate the difference between the bug start date and bug end date and so on). I find that the resolution time is indeed less than 5 days. So we accept the null hypothesis here i.e. resolution time is less than or equal to 5 business days. Wow, Hypothesis testing is very easy! Level of significance # Life is not easy always, Isn't it? In the above two cases, taking the samples was easy and our agreement / rejection of the null hypothesis was indeed accurate. In real life scenarios, we need to estimate a population parameter based on the sample and things might go wrong. That is to say, we might reject the null hypothesis when it is actually true or we might accept the null hypothesis when it is otherwise. This depends on the sample we take and if we don't have enough samples (or worse picked up wrong samples), things might go wrong. Say for example, the null hypothesis states that the mean of the population is greater than or equal to 500 i.e. \\mathbf{H}_\\mathbf{0}: \\mu \\ge 500 \\mathbf{H}_\\mathbf{0}: \\mu \\ge 500 and the alternate hypothesis is mean less than 500 \\mathbf{H}_\\mathbf{1}: \\mu < 500 \\mathbf{H}_\\mathbf{1}: \\mu < 500 Let's say, we took a sample size of 30 i.e n=30 and found the mean is 499 . Ah! now comes the dilemma - whether we need to accept or reject the null hypothesis? The sample mean is just falling short by 1 from the population mean. We go into self-doubt if we have taken the correct sample size or what happens if the sample size is increased or worst case, should I have to repeat the experiment once again and my manager fires me for wasting the time and effort? So, what we are contemplating here is the probability of the evidence (samples picked) being unfavorable to the null hypothesis. This probablility is called as the p-value If we say the p_value or probability is 2% , it means that our sample has 2% chances of going wrong in rejecting the null hypothesis. If we say the p_value or probability is 30% , it means that our sample has 30% chances of going wrong in rejecting the null hypothesis and our chances of getting a promotion will be adversely impacted. But, we are humans and we need to have a leeway (a threshold) for making some mistakes / error with the samples. This threshold is called as the level of significance In other words, level of significance is the maximum level of risk (maximum acceptable probability - in statistical terms) that we may take in rejecting the null hypothesis while the null hypothesis is actually true. Level of significance is denoted by the letter \\alpha \\alpha (alpha) alpha is normally represented as 1% or 5% or 10% etc. Let's consolidate our understanding! if the p-value is less than the level of significance , we reject the null hypothesis. if the p-value is greater than the level of significance , we accept the null hypothesis. Confused? Yeah, it happened with me. If not, I salute you. Proof for the 1 st statement Let's say the p-value is 2% and the level of significance is 5% . What does this mean? It means the probability of getting our samples wrong is 2% but the maximum risk that we can take is 5% . Correct? Remember our quest is always to prove the null hypothesis is wrong . In this case, our samples are within the permissible limits of going wrong and hence we reject the null hypothesis. Proof for the 2 nd statement Let's say the p-value is 10% and the level of significance is 5% . What does this mean? It means the probability of getting our samples wrong is 10% but the maximum risk that we can take is 5% . Correct? In this case, our samples are above the permissible limits of going wrong and hence we cannot reject the null hypothesis and have to accept the null hypothesis. Confidence level # When the null hypothesis is rejected with a level of significance of 5% , we may be questioned of how confident we are in rejecting the null hypothesis In other words, it is to say that what is our confidence level in rejecting the null hypothesis. The relationship between confidence level and the level of significance is given by the relation confidence \\space level = (1 - \\alpha) \\\\ confidence \\space level = (1 - \\alpha) \\\\ which in this case is confidence \\space level = (1 - 0.05) \\space = 0.95 confidence \\space level = (1 - 0.05) \\space = 0.95 which means, we need to have atleast 95% confidence level to reject the null hypothesis. Summary # To summarize, we have seen what is hypothesis, what is a null hypothesis, what is an alternate hypothesis and when hypothesis testing can go wrong. In the class, we have not seen the level of significance in detail and what important role it has in hypothesis testing. The last part of the article was included to make this grey area more clearer. Next post Hypothesis Test Process","title":"Hypothesis Testing"},{"location":"statistics/hypothesis_testing_01/#hypothesis_testing","text":"","title":"Hypothesis Testing"},{"location":"statistics/hypothesis_testing_01/#what_is_hypothesis_testing","text":"First let us understand what does the word hypothesis mean. Let us break the word into two parts hypo + thesis . What does thesis mean? thesis means something that has already been proven to be true. e.g Atleast 60% of the adult human body is made up of water. Sounds fine! So what does hypothesis mean? Hypothesis is something that is not yet been proven to be true. Let's come back to the original question! What is hypothesis testing? Can we say that it is the testing of hypothesis or more precisely the process of determining whether a given hypothesis is true or not To sum up, we take the hypothesis, we perform some statistical computations and prove if the hypothesis holds true or not.","title":"What is Hypothesis Testing?"},{"location":"statistics/hypothesis_testing_01/#null_hypothesis_alternate_hypothesis","text":"Null hypothesis is the assertion or belief that we hold as true unless we have sufficient evidence to prove otherwise. In statistical terms, we say it as the belief we hold about the value of a population parameter Remember Parameter is for the population and Statistic is for the sample Let's take an example and see what is the null hypothesis and how it is written. We believe that the mean of the population is 500 . Unless we obtain sufficient evidence that it is not 500 , our belief holds true i.e we accept that the mean is 500 So we can write it as null hypothesis: mean = 500 To write it more compactly, we can represent the same thing as \\mathbf{H}_\\mathbf{0} : \\mu = 500 \\mathbf{H}_\\mathbf{0} : \\mu = 500 where the symbol \\space\\mathbf{H}_\\mathbf{0} \\space\\mathbf{H}_\\mathbf{0} denotes Null hypothesis. The opposite of Null hypothesis is called as Alternate Hypothesis . That is, the negation of the null hypothesis. If there is a way to represent the null hypothesis, then there should be a way to represent the alternate hypothesis. Agreed? Ah, I see I have quoted a null hypothesis there! \\mathbf{H}_\\mathbf{1}: \\mu \\ne 500 \\mathbf{H}_\\mathbf{1}: \\mu \\ne 500 where the symbol \\space\\mathbf{H}_\\mathbf{1} \\space\\mathbf{H}_\\mathbf{1} denotes alternate hypothesis Note Since the null hypothesis and the alternate hypothesis are exactly opposite statements, only one can be true. Rejecting one is accepting the other.","title":"Null Hypothesis &amp; Alternate Hypothesis"},{"location":"statistics/hypothesis_testing_01/#level_of_significance","text":"Life is not easy always, Isn't it? In the above two cases, taking the samples was easy and our agreement / rejection of the null hypothesis was indeed accurate. In real life scenarios, we need to estimate a population parameter based on the sample and things might go wrong. That is to say, we might reject the null hypothesis when it is actually true or we might accept the null hypothesis when it is otherwise. This depends on the sample we take and if we don't have enough samples (or worse picked up wrong samples), things might go wrong. Say for example, the null hypothesis states that the mean of the population is greater than or equal to 500 i.e. \\mathbf{H}_\\mathbf{0}: \\mu \\ge 500 \\mathbf{H}_\\mathbf{0}: \\mu \\ge 500 and the alternate hypothesis is mean less than 500 \\mathbf{H}_\\mathbf{1}: \\mu < 500 \\mathbf{H}_\\mathbf{1}: \\mu < 500 Let's say, we took a sample size of 30 i.e n=30 and found the mean is 499 . Ah! now comes the dilemma - whether we need to accept or reject the null hypothesis? The sample mean is just falling short by 1 from the population mean. We go into self-doubt if we have taken the correct sample size or what happens if the sample size is increased or worst case, should I have to repeat the experiment once again and my manager fires me for wasting the time and effort? So, what we are contemplating here is the probability of the evidence (samples picked) being unfavorable to the null hypothesis. This probablility is called as the p-value If we say the p_value or probability is 2% , it means that our sample has 2% chances of going wrong in rejecting the null hypothesis. If we say the p_value or probability is 30% , it means that our sample has 30% chances of going wrong in rejecting the null hypothesis and our chances of getting a promotion will be adversely impacted. But, we are humans and we need to have a leeway (a threshold) for making some mistakes / error with the samples. This threshold is called as the level of significance In other words, level of significance is the maximum level of risk (maximum acceptable probability - in statistical terms) that we may take in rejecting the null hypothesis while the null hypothesis is actually true. Level of significance is denoted by the letter \\alpha \\alpha (alpha) alpha is normally represented as 1% or 5% or 10% etc.","title":"Level of significance"},{"location":"statistics/hypothesis_testing_01/#confidence_level","text":"When the null hypothesis is rejected with a level of significance of 5% , we may be questioned of how confident we are in rejecting the null hypothesis In other words, it is to say that what is our confidence level in rejecting the null hypothesis. The relationship between confidence level and the level of significance is given by the relation confidence \\space level = (1 - \\alpha) \\\\ confidence \\space level = (1 - \\alpha) \\\\ which in this case is confidence \\space level = (1 - 0.05) \\space = 0.95 confidence \\space level = (1 - 0.05) \\space = 0.95 which means, we need to have atleast 95% confidence level to reject the null hypothesis.","title":"Confidence level"},{"location":"statistics/hypothesis_testing_01/#summary","text":"To summarize, we have seen what is hypothesis, what is a null hypothesis, what is an alternate hypothesis and when hypothesis testing can go wrong. In the class, we have not seen the level of significance in detail and what important role it has in hypothesis testing. The last part of the article was included to make this grey area more clearer.","title":"Summary"},{"location":"statistics/hypothesis_testing_02/","text":"Hypothesis Tests # In the previous article , we got introduced to the concept of hypothesis - null hypothesis and the alternate hypothesis. We concluded with how the p-value is compared with the level of significance to either accept or reject the null hypothesis. We will keep p-value aside at the moment and will later see how it is calculated; less we know - less we are confused. Hypothesis test steps # Just to recap, hypothesis testing is the process of determining whether a given hypothesis is true or not The highlight is on the word process . If it is called a process, then there have to be some steps associated with it. The steps for testing the hypothesis are mentioned below State the null hypothesis \\mathbf{H}_\\mathbf{0} \\mathbf{H}_\\mathbf{0} and the alternate hypothesis \\mathbf{H}_\\mathbf{1} \\mathbf{H}_\\mathbf{1} Choose the level of significance Find critical values Find test statistic Draw your conclusion Ok. Sounds good! Let us take stock of what knowledge we have already about the above-mentioned steps. We know what the null and the alternate hypothesis are, level of significance, and probably presume what draw your conclusion means. What we don't know about at this point is Step 4 - Find critical values and Step 5 - find the test statistic. Good! Let's see what a critical value is! To understand the critical value and critical region, we need to first understand what one-tailed and two-tailed tests are. One-Tailed and Two-Tailed Tests # We have already seen tails in statistics - when there is a long tail to the right of a frequency distribution, the data is positively skewed and where is a long tail to the left, the data is negatively skewed. So it has to do something with the distribution curve? Yes, you are right! Let's dive into detail! What are tails? # In the day-to-day context, we know a tail is that extra portion that is attached to the body of an animal. Similarly, in the context of statistics, tails are that portion that is attached to the side of distribution - see figure below - the grey area Note Distribution does not have to have two tails always. There can be only one tail as well. Now that we have seen the tails visually, we understand things better. But, there are two tails here - do we have names that distinguish between these tails? Yes! It's upper tail and lower tail. The following image shows the lower tail and upper tail respectively. Upper tail The upper tail is towards the upper side i.e. the positive side of the graph (see image above). Remember positive values lie on the right of the graph (1, 2, 3, etc). So it is called as \"right-tail\" also. Lower tail The lower tail is towards the lower side i.e the negative side of the graph. Hence it is referred to as \"left-tail\" as well. So if the distribution has just one tail, it can be either an upper-tail or lower-tail and if the distribution has two-tails, it will have both upper-tail and lower-tail . Critical Region / Rejection Region The region that is shaded in grey i.e. the tail area is called as the Critical Region or Rejection Region The following image shows the rejection region for the lower-tailed graph Similarly, the image below depicts the rejection region for the upper tailed graph The rejection region for the two-tailed graph is shown below So far, so good!? Now in real-life problems, we will not be given the graph to understand if the tail is towards the left or right or it is two-tailed. The problem statement will be provided. We need to figure out the hypothesis and then decide if its right-tailed or left-tailed or both! One-Tailed tests # One-tailed tests can be either an upper tailed test or a lower tailed test. How can we spot or understand which tailed-tests the problem we have at hand belong to? Upper tail or lower tail? Remember in the previous article , we had stated the hypothesis for two examples. Let's revisit those examples. Example 1 My broadband company claims that the minimum internet speed they are providing is 150 Mbps. However, I suspect that they are not providing the promised internet speed. Let's write the null and alternate hypotheses for this! \\mathbf{H}_\\mathbf{0}: speed \\ge 150 Mbps \\\\ \\mathbf{H}_\\mathbf{1}: speed < 150 Mbps \\mathbf{H}_\\mathbf{0}: speed \\ge 150 Mbps \\\\ \\mathbf{H}_\\mathbf{1}: speed < 150 Mbps What we are trying to prove is our alternate hypothesis with evidence that the speed is less than 150 Mbps. So we see the symbol of alternate hypothesis i.e - if it is less than < 150 Mbps, it is called a lower tail test. Example 2 The project manager claims that the software defects raised are resolved within 5 business days. I being the quality department manager think it is taking longer to fix the bugs. The null and alternate hypothesis is mentioned below \\mathbf{H}_\\mathbf{0}: Resolution\\space period \\le 5 days \\\\ \\mathbf{H}_\\mathbf{1}: Resolution\\space period > 5 days \\mathbf{H}_\\mathbf{0}: Resolution\\space period \\le 5 days \\\\ \\mathbf{H}_\\mathbf{1}: Resolution\\space period > 5 days We see that the alternate hypothesis is greater than > 5 days. Hence, it is an upper-tail test. Important The upper-tailed test or lower-tailed test is determined based on the alternative hypothesis only and NOT the null hypothesis. To conclude, one-tailed tests can be either an upper-tail test or a lower-tail test and the test is determined by the symbol of the alternate hypothesis \\mathbf{H}_\\mathbf{1} \\mathbf{H}_\\mathbf{1} Two-Tailed tests # So how does the hypothesis of a two-tailed test look like? A residential school claims that the average time the students of the school get to do extra-curricular activities is 200 hours per year but, the parents doubt that the students spend so much time. The null and the alternate hypothesis looks like the below \\mathbf{H}_\\mathbf{0}: \\mu = 200 \\space hours \\\\ \\mathbf{H}_\\mathbf{1}: \\mu \\ne 200 \\space hours \\mathbf{H}_\\mathbf{0}: \\mu = 200 \\space hours \\\\ \\mathbf{H}_\\mathbf{1}: \\mu \\ne 200 \\space hours Here we see the symbol of the alternate hypothesis is \\ne \\ne which means the test is a two-tailed test. We don't check for increase or decrease i.e. \\ge \\ge or \\le \\le but, we check for a change in the parameter. So the critical region / tails are split over both the ends. Both the ends contain \\alpha/2 \\alpha/2 , making a total of \\alpha \\alpha - which is the level of significance. Refer to the previous article . Milestone reached: So from the hypothesis statement, we are understanding if the test is either a one-tailed (upper or lower tail) or two-tailed. We are still in step 3 - Finding the critical value Let's understand what a critical value is and then we will see how to compute the critical value. Critical value # We know what a critical region or a rejection region is! So critical value should be near or in that critical region. To take an analogy, the critical values of water - i.e. the boiling point is 100 deg Celcius and the freezing point is 0 deg Celcius. It is an important measure that helps us make important decisions. Definition of critical value A critical value is a line on a graph that splits the graph into sections. If our test value falls into that region, then you reject the null hypothesis - which means the samples and the evidence we had taken supports the alternate hypothesis Critical value depicted in the graph below - for lower-tailed graph Similarly, the critical value for the upper-tailed graph is below Critical values for a two-tailed graph is below In the case of a two-tailed graph, the value that we are computing should be either below or above the critical value for rejecting the null hypothesis. Ok - now we have visualized what a critical value is. This critical value is nothing but the 'Z' score We already know some of the common 'Z' scores. Example of a 'Z' score Let's say we have a sample normal distribution. We know that as per the empirical split (or rule), 68% lie within the 1 standard deviation from the mean, 95% lie within 2 standard deviation from the mean and 99.7% of the values lie within 3 standard deviations from the mean. We know that 'Z' score for +2.0 standard deviation is 1.96 and for -2.0 standard deviation is -1.96 . We have used this in several computations in the class. We will see how to compute 'Z' scores in another post. Let us see how the level of significance ( \\alpha \\alpha ) is used to find the critical value (Z score). Level of significance is covered in this post Critical value and level of significance # We use the level of significance ( \\alpha \\alpha ) to determine the critical value. How? Example: Determine the critical value at 5% level of significance. Presume its a right-tailed / upper-tailed test . We know \\alpha \\alpha = 5% (see image below to find where level of significance \\alpha \\alpha of 5% falls) and 1 - \\alpha \\alpha is 95% We know that 95% of the values fall within the 2 standard deviation mark and the corresponding the 'Z' score is 1.96 . So the critical value ( Z ) is 1.96 . So how will we determine if we have to accept or reject the null hypothesis? I am quoting a new word test statistic here. We will see what it is and how it is computed in the next post. At the moment, just think of test statistic as a number computed from our samples. If the test statistic ( test Z ) is less than the critical value ( Z ), we will accept the null hypothesis. In other words, we have not stepped into the rejection region and hence will accept. test\\space Z \\le Z : \\space accept \\space \\mathbf{H}_\\mathbf{0} \\\\ test\\space Z > Z : \\space reject \\space \\mathbf{H}_\\mathbf{0} test\\space Z \\le Z : \\space accept \\space \\mathbf{H}_\\mathbf{0} \\\\ test\\space Z > Z : \\space reject \\space \\mathbf{H}_\\mathbf{0} Let's visualize the above scenario with an example graph! The below are the numbers Critical value Z = 1.96 Test statistic ( test Z ) = 0.5 Since the test statistic is less than the critical value, we will accept the null hypothesis \\mathbf{H}_\\mathbf{0} \\mathbf{H}_\\mathbf{0} Summary # In this article, we focussed on the 3 rd step of the hypothesis testing process - Find the critical value We started with what are tails, upper tail and lower tail, one-tailed tests and two-tailed tests, critical region / rejection region, critical values and when to accept or reject the null hypothesis. In the next post, we will explore more on finding the test statistic which is the 4 th step of the hypothesis testing process. Next post Test statistic - Z and t","title":"Hypothesis Test Process"},{"location":"statistics/hypothesis_testing_02/#hypothesis_tests","text":"In the previous article , we got introduced to the concept of hypothesis - null hypothesis and the alternate hypothesis. We concluded with how the p-value is compared with the level of significance to either accept or reject the null hypothesis. We will keep p-value aside at the moment and will later see how it is calculated; less we know - less we are confused.","title":"Hypothesis Tests"},{"location":"statistics/hypothesis_testing_02/#hypothesis_test_steps","text":"Just to recap, hypothesis testing is the process of determining whether a given hypothesis is true or not The highlight is on the word process . If it is called a process, then there have to be some steps associated with it. The steps for testing the hypothesis are mentioned below State the null hypothesis \\mathbf{H}_\\mathbf{0} \\mathbf{H}_\\mathbf{0} and the alternate hypothesis \\mathbf{H}_\\mathbf{1} \\mathbf{H}_\\mathbf{1} Choose the level of significance Find critical values Find test statistic Draw your conclusion Ok. Sounds good! Let us take stock of what knowledge we have already about the above-mentioned steps. We know what the null and the alternate hypothesis are, level of significance, and probably presume what draw your conclusion means. What we don't know about at this point is Step 4 - Find critical values and Step 5 - find the test statistic. Good! Let's see what a critical value is! To understand the critical value and critical region, we need to first understand what one-tailed and two-tailed tests are.","title":"Hypothesis test steps"},{"location":"statistics/hypothesis_testing_02/#one-tailed_and_two-tailed_tests","text":"We have already seen tails in statistics - when there is a long tail to the right of a frequency distribution, the data is positively skewed and where is a long tail to the left, the data is negatively skewed. So it has to do something with the distribution curve? Yes, you are right! Let's dive into detail!","title":"One-Tailed and Two-Tailed Tests"},{"location":"statistics/hypothesis_testing_02/#what_are_tails","text":"In the day-to-day context, we know a tail is that extra portion that is attached to the body of an animal. Similarly, in the context of statistics, tails are that portion that is attached to the side of distribution - see figure below - the grey area Note Distribution does not have to have two tails always. There can be only one tail as well. Now that we have seen the tails visually, we understand things better. But, there are two tails here - do we have names that distinguish between these tails? Yes! It's upper tail and lower tail. The following image shows the lower tail and upper tail respectively.","title":"What are tails?"},{"location":"statistics/hypothesis_testing_02/#one-tailed_tests","text":"One-tailed tests can be either an upper tailed test or a lower tailed test. How can we spot or understand which tailed-tests the problem we have at hand belong to? Upper tail or lower tail? Remember in the previous article , we had stated the hypothesis for two examples. Let's revisit those examples. Example 1 My broadband company claims that the minimum internet speed they are providing is 150 Mbps. However, I suspect that they are not providing the promised internet speed. Let's write the null and alternate hypotheses for this! \\mathbf{H}_\\mathbf{0}: speed \\ge 150 Mbps \\\\ \\mathbf{H}_\\mathbf{1}: speed < 150 Mbps \\mathbf{H}_\\mathbf{0}: speed \\ge 150 Mbps \\\\ \\mathbf{H}_\\mathbf{1}: speed < 150 Mbps What we are trying to prove is our alternate hypothesis with evidence that the speed is less than 150 Mbps. So we see the symbol of alternate hypothesis i.e - if it is less than < 150 Mbps, it is called a lower tail test. Example 2 The project manager claims that the software defects raised are resolved within 5 business days. I being the quality department manager think it is taking longer to fix the bugs. The null and alternate hypothesis is mentioned below \\mathbf{H}_\\mathbf{0}: Resolution\\space period \\le 5 days \\\\ \\mathbf{H}_\\mathbf{1}: Resolution\\space period > 5 days \\mathbf{H}_\\mathbf{0}: Resolution\\space period \\le 5 days \\\\ \\mathbf{H}_\\mathbf{1}: Resolution\\space period > 5 days We see that the alternate hypothesis is greater than > 5 days. Hence, it is an upper-tail test. Important The upper-tailed test or lower-tailed test is determined based on the alternative hypothesis only and NOT the null hypothesis. To conclude, one-tailed tests can be either an upper-tail test or a lower-tail test and the test is determined by the symbol of the alternate hypothesis \\mathbf{H}_\\mathbf{1} \\mathbf{H}_\\mathbf{1}","title":"One-Tailed tests"},{"location":"statistics/hypothesis_testing_02/#two-tailed_tests","text":"","title":"Two-Tailed tests"},{"location":"statistics/hypothesis_testing_02/#critical_value","text":"We know what a critical region or a rejection region is! So critical value should be near or in that critical region. To take an analogy, the critical values of water - i.e. the boiling point is 100 deg Celcius and the freezing point is 0 deg Celcius. It is an important measure that helps us make important decisions.","title":"Critical value"},{"location":"statistics/hypothesis_testing_02/#critical_value_and_level_of_significance","text":"We use the level of significance ( \\alpha \\alpha ) to determine the critical value. How? Example: Determine the critical value at 5% level of significance. Presume its a right-tailed / upper-tailed test . We know \\alpha \\alpha = 5% (see image below to find where level of significance \\alpha \\alpha of 5% falls) and 1 - \\alpha \\alpha is 95% We know that 95% of the values fall within the 2 standard deviation mark and the corresponding the 'Z' score is 1.96 . So the critical value ( Z ) is 1.96 .","title":"Critical value and level of significance"},{"location":"statistics/hypothesis_testing_02/#summary","text":"In this article, we focussed on the 3 rd step of the hypothesis testing process - Find the critical value We started with what are tails, upper tail and lower tail, one-tailed tests and two-tailed tests, critical region / rejection region, critical values and when to accept or reject the null hypothesis. In the next post, we will explore more on finding the test statistic which is the 4 th step of the hypothesis testing process.","title":"Summary"},{"location":"statistics/hypothesis_testing_03/","text":"date modified: Mar 15, 2020 Test statistic - Z & t # In the previous article , we used test statistic as a value to compare against the critical value. This helps us to accept or reject our null hypothesis. In this article, we will see what is a test statistic and how to compute it. Note We are in the fourth step of the hypothesis testing process - Find the test statistic What is a test statistic? # A test statistic is used in a hypothesis test to decide to support or reject a null hypothesis. A test statistic is a number that is calculated from a sample and is compared with the null hypothesis. So what does this mean? We know that for the population we have parameters and for sample, we have statistics. i.e. any value that represents the population is called as parameter and any value that represents sample is called as a statistic We use this sample and come up with a value (statistic). This is called the test statistic. Methods of finding the test statistic # There are various methods/tests for finding the test statistic. Usually, the following four methods are used. Z test t test Chi-squared test ( \\chi^2 \\chi^2 ) F test In this article, we will cover the Z test and t test. We have these tests - how are they different? When the null hypothesis is about the mean of the population, the Z test or the t test is used. When the null hypothesis is about the variance of the population, the \\chi^2 \\chi^2 (chi-square) test and the F test is used. Let us see the Z test first. Z test # Assumptions of a Z test # Z test is used when the following conditions are met. The sample size n should be greater than 30 i.e. n > 30 n > 30 The population standard deviation should be known The variable should be continuous (remember, this is a continuous sampling distribution) Formula for Z test # The test statistic for Z test is represented as test Z The formula for finding the test statistic in a Z test is \\textrm {test}\\space Z = \\frac{\\bar{x} - \\mu} {\\sigma / \\sqrt n} \\textrm {test}\\space Z = \\frac{\\bar{x} - \\mu} {\\sigma / \\sqrt n} where \\bar{x} \\bar{x} is the sample mean, \\mu \\mu is the population mean, \\sigma \\sigma is the population standard deviation and n n is the number of samples. Example # Let's say the null and the alternate hypothesis are \\mathbf{H}_\\mathbf{0} : \\mu \\ge 1000 \\\\ \\mathbf{H}_\\mathbf{1} : \\mu < 1000 \\mathbf{H}_\\mathbf{0} : \\mu \\ge 1000 \\\\ \\mathbf{H}_\\mathbf{1} : \\mu < 1000 and the population standard deviation \\sigma \\sigma is known and a random sample of size n n = 30 is taken, then the test statistic of Z Z would be test\\space Z = \\frac{\\bar{x} - 1000}{\\sigma / \\sqrt 30} test\\space Z = \\frac{\\bar{x} - 1000}{\\sigma / \\sqrt 30} Let's check our understanding with a detailed example Let's highlight the keywords along with the problem statement An automatic bottling machine fills cola into 2-liter ( 2,000 - cubic cm) bottles. A consumer advocate wants to test the null hypothesis that the average amount filled by the machine into a bottle is at least 2,000 cubic cm . A random sample of 40 bottles coming out of the machine was selected and the exact contents of the selected bottles are recorded. The sample mean was 1,999.6 cubic cm . The population standard deviation is known from past experience to be 1.30 cubic cm. Test the null hypothesis at an \\alpha \\alpha of 5%. Let's write the values that have been provided \\mu = 2000; \\space n = 40; \\space \\bar{x} = 1999.6;\\space\\sigma=1.30; \\space \\alpha = 5% \\mu = 2000; \\space n = 40; \\space \\bar{x} = 1999.6;\\space\\sigma=1.30; \\space \\alpha = 5% Let's try to follow the hypothesis test process State the null and the alternate hypothesis Choose the level of significance Find the critical value Find the test statistic Draw the conclusion 1. Stating the null and the alternate hypothesis \\mathbf{H}_\\mathbf{0}: \\mu \\ge 2000 \\\\ \\mathbf{H}_\\mathbf{1}: \\mu < 2000 \\mathbf{H}_\\mathbf{0}: \\mu \\ge 2000 \\\\ \\mathbf{H}_\\mathbf{1}: \\mu < 2000 We see the sign of the alternate hypothesis and it is < (less than symbol) which means the test is a one-tailed lower-tail test. 2. Choose the level of significance The level of significance provided is \\alpha = 5 \\alpha = 5 %. So the confidence level is , 1 - \\alpha\\space = 95 \\alpha\\space = 95 % 3. Find the critical value The corresponding Z score (critical value) is z_c = -1.64 z_c = -1.64 Here the - (negative) sign implies that it is a lower tail test. Note The Z score for 95% is 1.64 but, since this is a lower-tailed test, we take the Z score as -1.64 The rejection region is highlighted in the graph below 4. Find the test statistic Here the sample is n = 40 n = 40 which means it confirms to the first condition of the Z Z test mentioned above Second, the population standard deviation is known - which means we can use the Z Z test to find the test statistic The formula for computing the Z Z score is \\textrm {test}\\space Z = \\frac{\\bar{x} - \\mu} {\\sigma / \\sqrt n} \\textrm {test}\\space Z = \\frac{\\bar{x} - \\mu} {\\sigma / \\sqrt n} When we substitute the values, we get \\textrm {test}\\space Z = \\frac{1999.6 - 2000} {1.30 / \\sqrt 40} \\textrm {test}\\space Z = \\frac{1999.6 - 2000} {1.30 / \\sqrt 40} which yeilds the result \\textrm {test} \\space z \\textrm {test} \\space z = -1.95 When we plot it in the graph, the graph would look like the below image The test statistic \\textrm{test} \\space z \\textrm{test} \\space z falls within the rejection range. Hence the null hypothesis will be rejected. 5. Drawing the conclusion The hypothesis that the average amount filled by the cola machine into a cola bottle is less than 2,000 cubic cm and hence, it is rejected. To sum up, the Z test is used to calculate the test statistic when the null hypothesis is about the means of the population and it satisfies the assumption mentioned above. 't' test or Student 't' test # We saw that the 'Z' test is applicable when the sample size is greater than 30 i.e. n>30 . There arises a logical question as to what test is to be done when the sample size is less than 30 i.e. n<30 . We use the 't' test for computing the test statistic for null hypothesis testing. Assumptions of a 't' test # t t test is used when the following conditions are met. The sample size n should be less than 30 i.e. n < 30 n < 30 The population standard deviation is not known irrespective of the sample size The population is normally distributed Formula for 't' test # t \\space statistic \\space (or \\space t\\space score), t= \\frac{\\bar{x} - \\mu}{s /\\sqrt n} t \\space statistic \\space (or \\space t\\space score), t= \\frac{\\bar{x} - \\mu}{s /\\sqrt n} where \\bar{x} \\bar{x} is the sample mean, \\mu \\mu is the population mean, s s is the sample standard deviation[^1] and n n is the number of samples. [^1] Since we don't know the population standard deviation in a 't' test, we use the sample standard deviation Characteristics of the 't' distribution it has degrees-of-freedom parameter df df it is symmetric and bell-shaped has wider tails than the Z distribution Extra_research Why does a t t distribution has wider tails than the Z distribution? In a t t distribution, the population standard deviation ( \\sigma \\sigma ) is not known and only the sample standard deviation ( s s ) is known. We know that by using the sample standard deviation, we cannot accurately project the population variance. Hence, to accommodate the level of uncertainity in computing the population variance, it has wider tails. As the degree of freedom ( df df ) increases, the t-distribution approaches the 'Z' distribution The 't' distribution with infinite degrees-of-freedom is called as the standard normal distribution. Confidence interval to estimate the population mean # As the population standard deviation, \\sigma \\sigma is not known in a t t , we will not able to estimate the population mean \\mu \\mu - but, we can find the range (confidence interval) of the population mean \\mu \\mu The formula for computing the confidence interval to estimate \\mu \\mu is \\bar{x} - t_{n-1,\\frac{\\alpha}{2}} \\frac{s}{\\sqrt n} \\le \\mu \\le \\bar{x} + t_{n-1,\\frac{\\alpha}{2}} \\frac{s}{\\sqrt n} \\bar{x} - t_{n-1,\\frac{\\alpha}{2}} \\frac{s}{\\sqrt n} \\le \\mu \\le \\bar{x} + t_{n-1,\\frac{\\alpha}{2}} \\frac{s}{\\sqrt n} where \\bar{x} \\bar{x} is the sample mean, t t is the test statistic of the t t distribution, n-1 n-1 is the degree of freedom, \\alpha \\alpha is the level of significance, S S is the sample standard deviation, n n is the number of samples. Why \\frac{\\alpha}{2} \\frac{\\alpha}{2} ? In a confidence interval, the area is symmetrically distributed between the two tails. Example # A stock market analyst wants to estimate the average return on a certain stock. A random sample of 15 days yields an average (annualized) return of \\bar{x} \\bar{x} 10.37% and a standard deviation of s = = 3.5%. Assuming a normal population of returns, give a 95% confidence interval for the average return on this stock. What we know here? Sample of 15 days i.e. s = 15 s = 15 (since sample is less than 30, t test is to be used) We need to use t distribution with n-1 n-1 degrees of freedom. So, df = 14 df = 14 . Sample standard deviation s = 3.5 s = 3.5 Sample mean \\bar{x} = 10.37 \\bar{x} = 10.37 Confidence level is 95%. So the level of significance deduced is 5%. Remember confidence level = 1 - \\alpha \\alpha which means \\alpha \\alpha = 100 - confidence level Solution We know the formula for the confidence interval of the t distribution is \\bar{x} - t_{n-1,\\frac{\\alpha}{2}} \\frac{s}{\\sqrt n} \\le \\mu \\le \\bar{x} + t_{n-1,\\frac{\\alpha}{2}} \\frac{s}{\\sqrt n} \\bar{x} - t_{n-1,\\frac{\\alpha}{2}} \\frac{s}{\\sqrt n} \\le \\mu \\le \\bar{x} + t_{n-1,\\frac{\\alpha}{2}} \\frac{s}{\\sqrt n} If we substitute the values, we get 10.37 - t_{14,0.025} \\frac{3.5}{\\sqrt 15} \\le \\mu \\le 10.37 + t_{14,0.025} \\frac{3.5}{\\sqrt 15} 10.37 - t_{14,0.025} \\frac{3.5}{\\sqrt 15} \\le \\mu \\le 10.37 + t_{14,0.025} \\frac{3.5}{\\sqrt 15} From the t tables, we can find the t statistic value for df = 14 df = 14 and \\alpha /2 = 0.025 \\alpha /2 = 0.025 is t_{14,0.025} = 2.145 t_{14,0.025} = 2.145 See below image for finding the t value for df = 14 df = 14 and \\alpha = 0.025 \\alpha = 0.025 Substituting in the formula, we get 10.37 - 2.145 \\frac{3.5}{\\sqrt 15} \\le \\mu \\le 10.37 + 2.145 \\frac{3.5}{\\sqrt 15} 10.37 - 2.145 \\frac{3.5}{\\sqrt 15} \\le \\mu \\le 10.37 + 2.145 \\frac{3.5}{\\sqrt 15} the confidence interval range is [8.43, 12.31] [8.43, 12.31] . This is represented as CI(0.05) = [8.43, 12.31] CI(0.05) = [8.43, 12.31] Thus, the analyst may be 95% sure that the average annualized return on the stock is anywhere from 8.43% to 12.31%. Degree of Freedom # Degrees of freedom refers to the maximum number of logically independent values in a data sample which have the freedom to vary within. What does that mean? We will take an example and try to understand. Example Let us consider that we have a sample of 3 values {5, x , 15} {5, x , 15} and the mean of all the values is 10. Note x x is unknown here It is easy to deduce that the value of x x would be 10 as the mean of these 3 values has to equate to 10. But, let's say 2 values from this sample are not known, {5, x, y} {5, x, y} Note ( x, y x, y are unknown) with the same mean 10, then we cannot be sure about the exact values of x x and y y . It could be any values of these values - (10, 15), (15, 10), (5, 20), (20, 5) or even (1, 24). So we cannot determine the exact value of these variables x x and y y . These 2 values have the freedom to vary. So, the degree of freedom ( df df ) of this sample data of size 3 is 2. Formula df = n \u2013 1 df = n \u2013 1 where df df is the degree of freedom and n n is the sample size Application of t-test # Your company wants to improve sales. Past sales data indicate that the average sale was $100 per transaction. After training your sales force, recent sales data (taken from a sample of 25 salesmen) indicates an average sale of $130, with a standard deviation of $15. Did the training work? Test your hypothesis at a 5% alpha level. What is given? From the problem, first, we need to understand if the given problem belongs to which category of tests - Z or t. The average sale is provided \\mu = 100 \\mu = 100 . Sample is n = 25 n = 25 . Recent sales data (sample) is given - ie. average sale \\bar{x} = 130 \\bar{x} = 130 . Sample standard deviation s = 15 s = 15 . Level of significance = 5% or 0.05 Since the sample size is less than 30 and we don't know the population standard deviation, we will go with the t test Solution Approach Did the training work? In other words, is there an increase in sales after the training is provided. Hypothesis testing steps We know the hypothesis testing steps State the null and the alternate hypothesis \\mathbf{H}_\\mathbf{0}: \\mu = 100 \\\\ \\mathbf{H}_\\mathbf{1}: \\mu > 100 \\mathbf{H}_\\mathbf{0}: \\mu = 100 \\\\ \\mathbf{H}_\\mathbf{1}: \\mu > 100 Since the symbol of the alternate hypothesis is greater than, it is a right-tailed test. Find the level of significance. Here the level of significance is provided - which is \\alpha = 0.05 \\alpha = 0.05 Find the critical value Since this is a t test, we need to use the t-table to find the critical value. The t-table has the degree of freedom and corresponding level of significance to provide the critical value. Here the degree of freedom df = n - 1 df = n - 1 which is 25 - 1 = 24 25 - 1 = 24 Looking into the critical table for df = 24 df = 24 and \\alpha = 0.05 \\alpha = 0.05 , we get the critical value t_c = 1.711 t_c = 1.711 (see figure below) Find the test statistic We know the formula for the t test is t_{score} = \\frac{\\bar{x} - \\mu}{s / \\sqrt n } t_{score} = \\frac{\\bar{x} - \\mu}{s / \\sqrt n } Substituting the above values, we get t_{score} = \\frac{130 - 100}{15 / \\sqrt 25} t_{score} = \\frac{130 - 100}{15 / \\sqrt 25} which gives us the t_{score} = 10 t_{score} = 10 Drawing the conclusions We see that the t_{score} t_{score} falls beyond the rejection region and hence the null hypothesis is rejected. This means to say that indeed the average sales increased after the training. Summary # In this article, we saw what a test statistic is!, the different types of tests, when to use Z test and t test and their respective formulas. In the end, we saw what is the degree of freedom along with an application of t-test using an example. We also got more familiar with the hypothesis testing process and following it would help us accept or reject the null hypothesis in a logical manner. Next post Test statistic - chi-square and F","title":"Test statistic - Z & t"},{"location":"statistics/hypothesis_testing_03/#test_statistic_-_z_t","text":"In the previous article , we used test statistic as a value to compare against the critical value. This helps us to accept or reject our null hypothesis. In this article, we will see what is a test statistic and how to compute it. Note We are in the fourth step of the hypothesis testing process - Find the test statistic","title":"Test statistic - Z &amp; t"},{"location":"statistics/hypothesis_testing_03/#what_is_a_test_statistic","text":"A test statistic is used in a hypothesis test to decide to support or reject a null hypothesis. A test statistic is a number that is calculated from a sample and is compared with the null hypothesis. So what does this mean? We know that for the population we have parameters and for sample, we have statistics. i.e. any value that represents the population is called as parameter and any value that represents sample is called as a statistic We use this sample and come up with a value (statistic). This is called the test statistic.","title":"What is a test statistic?"},{"location":"statistics/hypothesis_testing_03/#methods_of_finding_the_test_statistic","text":"There are various methods/tests for finding the test statistic. Usually, the following four methods are used. Z test t test Chi-squared test ( \\chi^2 \\chi^2 ) F test In this article, we will cover the Z test and t test. We have these tests - how are they different? When the null hypothesis is about the mean of the population, the Z test or the t test is used. When the null hypothesis is about the variance of the population, the \\chi^2 \\chi^2 (chi-square) test and the F test is used. Let us see the Z test first.","title":"Methods of finding the test statistic"},{"location":"statistics/hypothesis_testing_03/#z_test","text":"","title":"Z test"},{"location":"statistics/hypothesis_testing_03/#assumptions_of_a_z_test","text":"Z test is used when the following conditions are met. The sample size n should be greater than 30 i.e. n > 30 n > 30 The population standard deviation should be known The variable should be continuous (remember, this is a continuous sampling distribution)","title":"Assumptions of a Z test"},{"location":"statistics/hypothesis_testing_03/#formula_for_z_test","text":"The test statistic for Z test is represented as test Z The formula for finding the test statistic in a Z test is \\textrm {test}\\space Z = \\frac{\\bar{x} - \\mu} {\\sigma / \\sqrt n} \\textrm {test}\\space Z = \\frac{\\bar{x} - \\mu} {\\sigma / \\sqrt n} where \\bar{x} \\bar{x} is the sample mean, \\mu \\mu is the population mean, \\sigma \\sigma is the population standard deviation and n n is the number of samples.","title":"Formula for Z test"},{"location":"statistics/hypothesis_testing_03/#example","text":"Let's say the null and the alternate hypothesis are \\mathbf{H}_\\mathbf{0} : \\mu \\ge 1000 \\\\ \\mathbf{H}_\\mathbf{1} : \\mu < 1000 \\mathbf{H}_\\mathbf{0} : \\mu \\ge 1000 \\\\ \\mathbf{H}_\\mathbf{1} : \\mu < 1000 and the population standard deviation \\sigma \\sigma is known and a random sample of size n n = 30 is taken, then the test statistic of Z Z would be test\\space Z = \\frac{\\bar{x} - 1000}{\\sigma / \\sqrt 30} test\\space Z = \\frac{\\bar{x} - 1000}{\\sigma / \\sqrt 30}","title":"Example"},{"location":"statistics/hypothesis_testing_03/#t_test_or_student_t_test","text":"We saw that the 'Z' test is applicable when the sample size is greater than 30 i.e. n>30 . There arises a logical question as to what test is to be done when the sample size is less than 30 i.e. n<30 . We use the 't' test for computing the test statistic for null hypothesis testing.","title":"'t' test or Student 't' test"},{"location":"statistics/hypothesis_testing_03/#assumptions_of_a_t_test","text":"t t test is used when the following conditions are met. The sample size n should be less than 30 i.e. n < 30 n < 30 The population standard deviation is not known irrespective of the sample size The population is normally distributed","title":"Assumptions of a 't' test"},{"location":"statistics/hypothesis_testing_03/#formula_for_t_test","text":"t \\space statistic \\space (or \\space t\\space score), t= \\frac{\\bar{x} - \\mu}{s /\\sqrt n} t \\space statistic \\space (or \\space t\\space score), t= \\frac{\\bar{x} - \\mu}{s /\\sqrt n} where \\bar{x} \\bar{x} is the sample mean, \\mu \\mu is the population mean, s s is the sample standard deviation[^1] and n n is the number of samples. [^1] Since we don't know the population standard deviation in a 't' test, we use the sample standard deviation","title":"Formula for 't' test"},{"location":"statistics/hypothesis_testing_03/#confidence_interval_to_estimate_the_population_mean","text":"As the population standard deviation, \\sigma \\sigma is not known in a t t , we will not able to estimate the population mean \\mu \\mu - but, we can find the range (confidence interval) of the population mean \\mu \\mu The formula for computing the confidence interval to estimate \\mu \\mu is \\bar{x} - t_{n-1,\\frac{\\alpha}{2}} \\frac{s}{\\sqrt n} \\le \\mu \\le \\bar{x} + t_{n-1,\\frac{\\alpha}{2}} \\frac{s}{\\sqrt n} \\bar{x} - t_{n-1,\\frac{\\alpha}{2}} \\frac{s}{\\sqrt n} \\le \\mu \\le \\bar{x} + t_{n-1,\\frac{\\alpha}{2}} \\frac{s}{\\sqrt n} where \\bar{x} \\bar{x} is the sample mean, t t is the test statistic of the t t distribution, n-1 n-1 is the degree of freedom, \\alpha \\alpha is the level of significance, S S is the sample standard deviation, n n is the number of samples.","title":"Confidence interval to estimate the population mean"},{"location":"statistics/hypothesis_testing_03/#example_1","text":"A stock market analyst wants to estimate the average return on a certain stock. A random sample of 15 days yields an average (annualized) return of \\bar{x} \\bar{x} 10.37% and a standard deviation of s = = 3.5%. Assuming a normal population of returns, give a 95% confidence interval for the average return on this stock.","title":"Example"},{"location":"statistics/hypothesis_testing_03/#degree_of_freedom","text":"Degrees of freedom refers to the maximum number of logically independent values in a data sample which have the freedom to vary within. What does that mean? We will take an example and try to understand.","title":"Degree of Freedom"},{"location":"statistics/hypothesis_testing_03/#application_of_t-test","text":"Your company wants to improve sales. Past sales data indicate that the average sale was $100 per transaction. After training your sales force, recent sales data (taken from a sample of 25 salesmen) indicates an average sale of $130, with a standard deviation of $15. Did the training work? Test your hypothesis at a 5% alpha level.","title":"Application of t-test"},{"location":"statistics/hypothesis_testing_03/#summary","text":"In this article, we saw what a test statistic is!, the different types of tests, when to use Z test and t test and their respective formulas. In the end, we saw what is the degree of freedom along with an application of t-test using an example. We also got more familiar with the hypothesis testing process and following it would help us accept or reject the null hypothesis in a logical manner.","title":"Summary"},{"location":"statistics/hypothesis_testing_04/","text":"Test statistic - \\chi^2 \\chi^2 & F # In the previous article , we saw what a Z test and t-test are! Z test and t-test are used when the hypothesis test is about the means of the population. In this article, let us see two tests - the chi-squared ( \\chi^2 \\chi^2 ) and F test which tests the hypothesis about the variance of the population. Recall The sample estimate of the population variance is given by $$ s^2 = \\frac{\\sum(x_i-\\bar{x})^2}{n-1} $$ where s s is the sample variance, \\bar{x} \\bar{x} is the sample mean, and n n is the number of samples. Chi-squared statistic # \\chi^2 \\chi^2 is used to test the hypothesis about a single population variance. Formula # The formula for computing \\chi ^2 \\chi ^2 is \\chi ^2 = \\frac{(n-1)s ^2}{\\sigma ^2} \\chi ^2 = \\frac{(n-1)s ^2}{\\sigma ^2} where df df is the degree of freedom, s s is the sample standard deviation and \\sigma \\sigma is the population standard deviation and n n is the number of samples. Interpretation of \\chi ^2 \\chi ^2 If the chi-square value is more than the critical value, then there is a significant difference in the variance between the sample and the population. Tip The Chi-square statistic can only be used on numbers . They can\u2019t be used for percentages, proportions, means or similar statistical value. For example, if you have 20 percent of 100 people, you would need to convert that to a number (20) before you can run a test statistic. Application of Chi-square # A manufacturing company produces bearings of 2.65 cm in diameter. A major customer requires that the variance in diameter be no more than 0.001 cm ^2 cm ^2 . The manufacturer tests 20 bearings using a precise instrument and gets the below values. Assuming the diameters are normally distributed, can the population of these bearings be rejected due to high variance at 1% significance level. Data 2.69, 2.66, 2.64, 2.59, 2.62, 2.63, 2.69, 2.66, 2.63, 2.65, 2.57, 2.63, 2.70, 2.71, 2.64, 2.65, 2.59, 2.66, 2.62, 2.57 Solution approach # The problem talks about a single population variance. Hence, a \\chi ^2 \\chi ^2 test can be used. Known parameters sample \\space size \\space n = 20 sample \\space size \\space n = 20 level \\space of \\space significance \\space \\alpha = 1\\% \\space or \\space 0.01 level \\space of \\space significance \\space \\alpha = 1\\% \\space or \\space 0.01 Degree \\space of \\space freedom \\space = n - 1 \\space which \\space is \\space 20 - 1 \\space = 19 Degree \\space of \\space freedom \\space = n - 1 \\space which \\space is \\space 20 - 1 \\space = 19 population \\space variance = \\sigma ^2 = 0.001 population \\space variance = \\sigma ^2 = 0.001 Let's follow the hypothesis testing process State the null and the alternate hypothesis. The variance in diameter to be no more than 0.001 cm ^2 cm ^2 . So the null hypothesis is \\mathbf{H}_\\mathbf{0}: diameter \\le 0.001 \\mathbf{H}_\\mathbf{0}: diameter \\le 0.001 and hence the alternate hypothesis is \\mathbf{H}_\\mathbf{1} : diameter > 0.001 \\mathbf{H}_\\mathbf{1} : diameter > 0.001 Since the alternate hypothesis has the greater than symbol > > , it is a chi-square right-tailed test. Find the level of significance The level of significance is already provided \\alpha = 0.05 \\alpha = 0.05 Tip If the level of significance is not provided, take the default \\alpha = 0.05 \\alpha = 0.05 Find the critical value The critical value is found out in the chi-squared table for df = 19 df = 19 and \\alpha = 0.01 \\alpha = 0.01 . The critical value is 36.191. i.e \\chi ^2_c = 36.191 \\chi ^2_c = 36.191 Find the test statistic To find the test statistic, we will use the formula. \\chi ^2 = \\frac{(n-1)s ^2}{\\sigma ^2} \\chi ^2 = \\frac{(n-1)s ^2}{\\sigma ^2} We don't know the sample variance s ^2 s ^2 but, it can be computed by using the data provided. Copy the data in excel and use the formula VAR.S and get the value which in turn is 0.001621 0.001621 . Substituting the values, we get \\chi ^2 = \\frac{19 *0.001621}{0.001} \\chi ^2 = \\frac{19 *0.001621}{0.001} which gives \\chi ^2 = 30.8 \\chi ^2 = 30.8 Draw the conclusion - to accept/reject the null hypothesis Since the \\chi ^2 < \\chi^2_{critical} \\chi ^2 < \\chi^2_{critical} i.e. 30.8 < 36.191 30.8 < 36.191 , we accept the null hypothesis. The bearings produced are within the specified limits required by the customer. To conclude, a \\chi ^2 \\chi ^2 test (chi-squared) is used to test the hypothesis about a single population variance. F distribution # \\chi ^2 \\chi ^2 is useful when testing hypothesis about a single population. What if we want to test the hypothesis about the difference in variances of two populations? Example Do parts manufactured on 2 different machines have the same variance or not? Formula # Since F-test is a comparison of variances of two different populations using samples collected from each population, we can say that it is the ratio of two sample variances i.e. F = \\frac{s_1 ^2}{s_2 ^2} = \\frac{est.\\sigma ^2_1}{est.\\sigma ^2_2} F = \\frac{s_1 ^2}{s_2 ^2} = \\frac{est.\\sigma ^2_1}{est.\\sigma ^2_2} What does this formula mean? We know that s_1 s_1 is the standard deviation of sample 1 and s_2 s_2 is the standard deviation of sample 2. Since the F test is a comparison between two variances , we need to square the standard deviation. (Remember: variance = standard deviation ^2 ^2 ) Interpretation Ideally, this F ratio should be about 1 if the 2 samples come from the same population or the 2 samples come from a different population with the same variance So if we compute the F ratio and see if the value is near to 1, it means two samples have the same variance thereby the population variance is also the same. Bigger the F ratio - bigger the variance (or the two population is not related to each other) Important Since the F test/distribution deals with two samples, there will be two degrees of freedom - one for sample 1 and one for sample 2. Facts The curve is not symmetrical but skewed to the right. There is a different curve for each set of df . The F statistic is greater than or equal to zero. As the degrees of freedom for the numerator and the denominator get larger, the curve approximates the normal. Application of the 'F' test # A machine produces metal sheets with 22mm thickness. There is a variability in thickness due to machines, operators, manufacturing environment, raw material, etc. The company wants to know the consistency of two machines and randomly samples 10 sheets from machine 1 and 12 sheets from machine 2. Thickness measurements are taken. Assume sheet thickness is normally distributed in the population. The company wants to know if the variance for each sample comes from the same population variance (i.e. population variances are equal) or from different population variances (population variances are unequal). Data provided Machine 1 Machine 2 22.3 22.0 21.8 22.1 22.3 21.8 21.6 21.9 21.8 22.2 21.9 22.0 22.4 21.7 22.5 21.9 22.2 22.0 21.6 22.1 21.9 22.1 Solution Approach # Understanding what type of test it is Here the problem statement is about knowing the consistency of two machines in terms of variability . For variances test, we have two tests - \\chi ^2 \\chi ^2 and F test. But since we have to compare two variances, we have to go with the F test. Known parameters Samples \\space from \\space machine \\space one \\space n_1 = 10 \\\\ Samples \\space from \\space machine \\space two \\space n_2 = 12 Samples \\space from \\space machine \\space one \\space n_1 = 10 \\\\ Samples \\space from \\space machine \\space two \\space n_2 = 12 We have the data for machine 1 and machine 2 - from which we can find the variance - from excel Compute the rest of the parameters We compute the variance and the count of samples. The degree of freedom for machine 1 is 9 ( df_1 = n_1 - 1 df_1 = n_1 - 1 ). The degree of freedom for machine 1 is 11 ( df_2 = n_2 - 1 df_2 = n_2 - 1 ). Following the hypothesis testing process There are 5 steps to the hypothesis testing process. Let's follow that one by one. State the null and the alternate hypothesis Since this problem talks about variance in the two machines, the null hypothesis will be that there is no variance. \\mathbf{H}_\\mathbf{0}: \\sigma_1 ^2 = \\sigma_2 ^2 \\mathbf{H}_\\mathbf{0}: \\sigma_1 ^2 = \\sigma_2 ^2 The alternate hypothesis will be \\mathbf{H}_\\mathbf{0}: \\sigma_1 ^2 \\ne \\sigma_2 ^2 \\mathbf{H}_\\mathbf{0}: \\sigma_1 ^2 \\ne \\sigma_2 ^2 So based on the symbol of the alternate hypothesis which is \\ne \\ne , we conclude that this is a two-tailed test. Tip If there is any difficulty in stating the null hypothesis, start with the alternate hypothesis and then draft the null hypothesis. Find the level of significance The level of significance \\alpha \\alpha is not given and hence a \\alpha \\alpha of 5% or 0.05 is presumed. Since this is a two-tailed test, we have to divide \\alpha \\alpha by 2 which gives the value as 0.025. Find the critical value Similar to tables for other tests, F tests also have a corresponding table called the F-table. The F-table has a degree of freedom one ( df_1 df_1 ) on the 'x' axis and degree of freedom two ( df_2 df_2 ) on the 'y' axis. Let's see the F table for df_1 = 9 df_1 = 9 and df_2 = 11 df_2 = 11 to find the critical value for F test. The critical value is F_{0.025,9,11} = 3.5879 F_{0.025,9,11} = 3.5879 . This number is for the right-tail. Remember, we have a two-tails for this hypothesis testing. We also need to compute the left-tail critical value which can be either computed like the F-table above with a level of significance \\alpha = 0.975 (1-0.025 = 0.975) \\alpha = 0.975 (1-0.025 = 0.975) and the df_1 = 9 df_1 = 9 and df_2 = 11 df_2 = 11 . The other method of doing this is to divide 1 by F_{0.025,9,11} F_{0.025,9,11} F_{0.975,9,11} = \\frac{1}{F_{0.025,9,11}} F_{0.975,9,11} = \\frac{1}{F_{0.025,9,11}} F_{0.975,9,11} = \\frac{1}{3.5879} = 0.2787 F_{0.975,9,11} = \\frac{1}{3.5879} = 0.2787 Find the test statistic The test statistic is found by the F distribution formula - which is F = \\frac{s_1 ^2}{s_2 ^2} F = \\frac{s_1 ^2}{s_2 ^2} So the F score is 5.62 $$ F_{score} = \\frac{0.11378}{0.02023} = 5.62 $$ Draw the conclusion From the above steps, we know that the F_{critical} = 3.5879 F_{critical} = 3.5879 and the F_{score} = 5.62 F_{score} = 5.62 Since F_{score} F_{score} > F_{critical} F_{critical} or in other words, falls into the rejection region, we reject the null hypothesis. That is, the variance in Machine 1 and Machine 2 are not equal. Machine 1 has a higher variance and hence needs to be inspected for issues. The graph below illustrates the F score and the F critical value and why the null hypothesis is rejected. ANOVA # ANOVA - Analysis of Variance ANOVA is used to analyze the means of the samples. In the \\chi^2 \\chi^2 test, we saw how to compare variance within a single population and in the F test, we saw how to compare the variance between two samples of a single population / two population. What if there are three or more samples? Can we find if they are from the same population? ANOVA test is used for this purpose. When performing ANOVA test, we try to determine if the difference between the averages reflects a real difference between the groups, or is due to the random noise inside each group. The groups here mean samples - say out of a Population p, we are taking three groups of samples - n_1, n_2, n_3 n_1, n_2, n_3 . Assumptions in the ANOVA test # The samples taken are independent; (taking samples in one group does not affect the probability of the samples taken in other groups) The population must be normally distributed. Null hypothesis and computation # Since we are comparing three groups or more, the null hypothesis of ANOVA would look like below \\mathbf{H}_\\mathbf{0}: \\mu_A = \\mu_B = \\mu_C \\mathbf{H}_\\mathbf{0}: \\mu_A = \\mu_B = \\mu_C We compute the F value and compare it with the critical value determined by the degrees of freedom. Here, the degrees of freedom are to be calculated for the groups and the number of items in each group. Example # Let's say we have three groups - A, B and C which have the below samples picked. Group A Group B Group C 37 62 50 60 27 63 52 69 58 43 64 54 40 43 49 52 54 52 55 44 53 39 31 43 39 49 65 23 57 43 These three groups have an equal number of samples. The degree of freedom of the groups = df_g = 3 - 1 = 2 df_g = 3 - 1 = 2 . The degree of freedom for the samples within each group is df_s = 9 + 9 + 9 = 27 df_s = 9 + 9 + 9 = 27 i.e. n-1 n-1 for each group which is 10 - 1 = 9 10 - 1 = 9 Let us calculate the mean of each of the groups and the total mean (which is total of all the means of the three groups divided by 3) Group A Group B Group C 37 62 50 60 27 63 52 69 58 43 64 54 40 43 49 52 54 52 55 44 53 39 31 43 39 49 65 23 57 43 Mean 44 50 53 Mean Total 49 Important ANOVA considers two types of variance Between groups How far each group mean vary from the total mean (i.e. in this case, how 44, 50, 53 44, 50, 53 vary from the total mean 49 49 Within groups How far individual values vary from their respective group mean. Note We will compute the F score both manually as well as using excel. If you want to move on with excel computation only, you may skip the below section and can proceed with computation with excel (using data-analysis addin) only. Formula # We compute F value for the groups which is the ratio between the two variances - i.e. variance between groups and variance within groups F = \\frac{Variance\\space Between\\space Groups}{Variance\\space Within\\space Groups} F = \\frac{Variance\\space Between\\space Groups}{Variance\\space Within\\space Groups} Recall We know that the formula for variance is $$ s ^2 = \\frac{\\sum(x - \\bar{x}) ^2}{n -1} = \\frac{SS}{df} $$ where \\sum(x - \\bar{x}) ^2 \\sum(x - \\bar{x}) ^2 is the sum of squares SS SS and the n -1 n -1 is the degree of freedom . So the formula for the f value becomes F = \\frac{VarianceBetweenGroups}{VarianceWithinGroups} = \\frac{\\frac{SSG}{df_{groups}}}{\\frac{SSE}{df_{error}}} F = \\frac{VarianceBetweenGroups}{VarianceWithinGroups} = \\frac{\\frac{SSG}{df_{groups}}}{\\frac{SSE}{df_{error}}} where SSG SSG = Sum of squares groups, df_{groups} = df_{groups} = degrees of freedom (groups) and SSE SSE = Sum of squares error and df_{error} df_{error} = degrees of freedom (error) Solution approach # As with any hypothesis testing, let us perform the calculation using the hypothesis testing steps. State the null and the alternate hypothesis For ANOVA, the hypothesis will always be - the means across different groups will be equal. In this case, the means of the groups will be equal is the null hypothesis. \\mathbf{H}_\\mathbf{0}: \\mu_A = \\mu_B = \\mu_C \\mathbf{H}_\\mathbf{0}: \\mu_A = \\mu_B = \\mu_C The alternate hypothesis will be \\mathbf{H}_\\mathbf{1}: \\mu_A \\ne \\mu_B \\ne \\mu_C \\mathbf{H}_\\mathbf{1}: \\mu_A \\ne \\mu_B \\ne \\mu_C Important In ANOVA, there will be NO two-tailed test. ANOVA will ALWAYS be one-tailed and that will be upper-tailed only . Why? We know that in the formula, we are dividing the sum of squares between groups and within groups which would always yield a positive value and hence it will always be upper tailed . Find the level of significance Here level of significance is not provided; we will take the default \\alpha = 0.05 \\alpha = 0.05 Find the critical value We know that the two degrees of freedom - for the groups and within the groups are 2 and 27 respectively. So, df_1 = 2 df_1 = 2 and df_2 = 27 df_2 = 27 Looking into the F table (for ANOVA) at 0.05 significance level, we get the F_{critical} F_{critical} value as 3.35 3.35 (see image below) Find the test statistic To compute it manually, we will be using excel. The following screenshot shows how it is done. We know the formula is F = \\frac{VarianceBetweenGroups}{VarianceWithinGroups} = \\frac{\\frac{SSG}{df_{groups}}}{\\frac{SSE}{df_{error}}} F = \\frac{VarianceBetweenGroups}{VarianceWithinGroups} = \\frac{\\frac{SSG}{df_{groups}}}{\\frac{SSE}{df_{error}}} Computing the sum of squares within groups and between groups manually. substituting in the formula, we get F_{test} = \\frac{\\frac{420}{2}}{\\frac{3300}{27}} = 1.718 F_{test} = \\frac{\\frac{420}{2}}{\\frac{3300}{27}} = 1.718 Computing the sum of squares within groups and between groups via excel data-analysis addin. Enter the data in excel Go to Data -> Data Analysis and select \"Anova - Single factor\" and click \"OK\" Give the input range, check \"labels in first row\" as we have the group headers in the first row and input the level of significance. Click \"OK\" We get the analysis in a new sheet. Draw your conclusion Here we see that the F_{score} F_{score} is less than the F_{critical} F_{critical} ( 1.718 < 3.354 1.718 < 3.354 ) and hence we will accept the null hypothesis - which means that there is no difference between the means of any group. Summary # To summarize, we have seen two tests - the chi-square and the F test to test the variances in the population. We have also seen ANOVA - which is used to test the hypothesis when more than two groups of samples are picked from the population.","title":"Test statistic - Chi-square & F"},{"location":"statistics/hypothesis_testing_04/#test_statistic_-_chi2chi2_f","text":"In the previous article , we saw what a Z test and t-test are! Z test and t-test are used when the hypothesis test is about the means of the population. In this article, let us see two tests - the chi-squared ( \\chi^2 \\chi^2 ) and F test which tests the hypothesis about the variance of the population. Recall The sample estimate of the population variance is given by $$ s^2 = \\frac{\\sum(x_i-\\bar{x})^2}{n-1} $$ where s s is the sample variance, \\bar{x} \\bar{x} is the sample mean, and n n is the number of samples.","title":"Test statistic - \\chi^2\\chi^2 &amp; F"},{"location":"statistics/hypothesis_testing_04/#chi-squared_statistic","text":"\\chi^2 \\chi^2 is used to test the hypothesis about a single population variance.","title":"Chi-squared statistic"},{"location":"statistics/hypothesis_testing_04/#formula","text":"The formula for computing \\chi ^2 \\chi ^2 is \\chi ^2 = \\frac{(n-1)s ^2}{\\sigma ^2} \\chi ^2 = \\frac{(n-1)s ^2}{\\sigma ^2} where df df is the degree of freedom, s s is the sample standard deviation and \\sigma \\sigma is the population standard deviation and n n is the number of samples.","title":"Formula"},{"location":"statistics/hypothesis_testing_04/#application_of_chi-square","text":"A manufacturing company produces bearings of 2.65 cm in diameter. A major customer requires that the variance in diameter be no more than 0.001 cm ^2 cm ^2 . The manufacturer tests 20 bearings using a precise instrument and gets the below values. Assuming the diameters are normally distributed, can the population of these bearings be rejected due to high variance at 1% significance level.","title":"Application of Chi-square"},{"location":"statistics/hypothesis_testing_04/#solution_approach","text":"The problem talks about a single population variance. Hence, a \\chi ^2 \\chi ^2 test can be used.","title":"Solution approach"},{"location":"statistics/hypothesis_testing_04/#f_distribution","text":"\\chi ^2 \\chi ^2 is useful when testing hypothesis about a single population. What if we want to test the hypothesis about the difference in variances of two populations? Example Do parts manufactured on 2 different machines have the same variance or not?","title":"F distribution"},{"location":"statistics/hypothesis_testing_04/#formula_1","text":"Since F-test is a comparison of variances of two different populations using samples collected from each population, we can say that it is the ratio of two sample variances i.e. F = \\frac{s_1 ^2}{s_2 ^2} = \\frac{est.\\sigma ^2_1}{est.\\sigma ^2_2} F = \\frac{s_1 ^2}{s_2 ^2} = \\frac{est.\\sigma ^2_1}{est.\\sigma ^2_2} What does this formula mean? We know that s_1 s_1 is the standard deviation of sample 1 and s_2 s_2 is the standard deviation of sample 2. Since the F test is a comparison between two variances , we need to square the standard deviation. (Remember: variance = standard deviation ^2 ^2 )","title":"Formula"},{"location":"statistics/hypothesis_testing_04/#application_of_the_f_test","text":"A machine produces metal sheets with 22mm thickness. There is a variability in thickness due to machines, operators, manufacturing environment, raw material, etc. The company wants to know the consistency of two machines and randomly samples 10 sheets from machine 1 and 12 sheets from machine 2. Thickness measurements are taken. Assume sheet thickness is normally distributed in the population. The company wants to know if the variance for each sample comes from the same population variance (i.e. population variances are equal) or from different population variances (population variances are unequal).","title":"Application of the 'F' test"},{"location":"statistics/hypothesis_testing_04/#solution_approach_1","text":"","title":"Solution Approach"},{"location":"statistics/hypothesis_testing_04/#anova","text":"ANOVA - Analysis of Variance ANOVA is used to analyze the means of the samples. In the \\chi^2 \\chi^2 test, we saw how to compare variance within a single population and in the F test, we saw how to compare the variance between two samples of a single population / two population. What if there are three or more samples? Can we find if they are from the same population? ANOVA test is used for this purpose. When performing ANOVA test, we try to determine if the difference between the averages reflects a real difference between the groups, or is due to the random noise inside each group. The groups here mean samples - say out of a Population p, we are taking three groups of samples - n_1, n_2, n_3 n_1, n_2, n_3 .","title":"ANOVA"},{"location":"statistics/hypothesis_testing_04/#assumptions_in_the_anova_test","text":"The samples taken are independent; (taking samples in one group does not affect the probability of the samples taken in other groups) The population must be normally distributed.","title":"Assumptions in the ANOVA test"},{"location":"statistics/hypothesis_testing_04/#null_hypothesis_and_computation","text":"Since we are comparing three groups or more, the null hypothesis of ANOVA would look like below \\mathbf{H}_\\mathbf{0}: \\mu_A = \\mu_B = \\mu_C \\mathbf{H}_\\mathbf{0}: \\mu_A = \\mu_B = \\mu_C We compute the F value and compare it with the critical value determined by the degrees of freedom. Here, the degrees of freedom are to be calculated for the groups and the number of items in each group.","title":"Null hypothesis and computation"},{"location":"statistics/hypothesis_testing_04/#example","text":"Let's say we have three groups - A, B and C which have the below samples picked. Group A Group B Group C 37 62 50 60 27 63 52 69 58 43 64 54 40 43 49 52 54 52 55 44 53 39 31 43 39 49 65 23 57 43 These three groups have an equal number of samples. The degree of freedom of the groups = df_g = 3 - 1 = 2 df_g = 3 - 1 = 2 . The degree of freedom for the samples within each group is df_s = 9 + 9 + 9 = 27 df_s = 9 + 9 + 9 = 27 i.e. n-1 n-1 for each group which is 10 - 1 = 9 10 - 1 = 9 Let us calculate the mean of each of the groups and the total mean (which is total of all the means of the three groups divided by 3) Group A Group B Group C 37 62 50 60 27 63 52 69 58 43 64 54 40 43 49 52 54 52 55 44 53 39 31 43 39 49 65 23 57 43 Mean 44 50 53 Mean Total 49 Important ANOVA considers two types of variance Between groups How far each group mean vary from the total mean (i.e. in this case, how 44, 50, 53 44, 50, 53 vary from the total mean 49 49 Within groups How far individual values vary from their respective group mean. Note We will compute the F score both manually as well as using excel. If you want to move on with excel computation only, you may skip the below section and can proceed with computation with excel (using data-analysis addin) only.","title":"Example"},{"location":"statistics/hypothesis_testing_04/#formula_2","text":"We compute F value for the groups which is the ratio between the two variances - i.e. variance between groups and variance within groups F = \\frac{Variance\\space Between\\space Groups}{Variance\\space Within\\space Groups} F = \\frac{Variance\\space Between\\space Groups}{Variance\\space Within\\space Groups} Recall We know that the formula for variance is $$ s ^2 = \\frac{\\sum(x - \\bar{x}) ^2}{n -1} = \\frac{SS}{df} $$ where \\sum(x - \\bar{x}) ^2 \\sum(x - \\bar{x}) ^2 is the sum of squares SS SS and the n -1 n -1 is the degree of freedom . So the formula for the f value becomes F = \\frac{VarianceBetweenGroups}{VarianceWithinGroups} = \\frac{\\frac{SSG}{df_{groups}}}{\\frac{SSE}{df_{error}}} F = \\frac{VarianceBetweenGroups}{VarianceWithinGroups} = \\frac{\\frac{SSG}{df_{groups}}}{\\frac{SSE}{df_{error}}} where SSG SSG = Sum of squares groups, df_{groups} = df_{groups} = degrees of freedom (groups) and SSE SSE = Sum of squares error and df_{error} df_{error} = degrees of freedom (error)","title":"Formula"},{"location":"statistics/hypothesis_testing_04/#solution_approach_2","text":"As with any hypothesis testing, let us perform the calculation using the hypothesis testing steps. State the null and the alternate hypothesis For ANOVA, the hypothesis will always be - the means across different groups will be equal. In this case, the means of the groups will be equal is the null hypothesis. \\mathbf{H}_\\mathbf{0}: \\mu_A = \\mu_B = \\mu_C \\mathbf{H}_\\mathbf{0}: \\mu_A = \\mu_B = \\mu_C The alternate hypothesis will be \\mathbf{H}_\\mathbf{1}: \\mu_A \\ne \\mu_B \\ne \\mu_C \\mathbf{H}_\\mathbf{1}: \\mu_A \\ne \\mu_B \\ne \\mu_C Important In ANOVA, there will be NO two-tailed test. ANOVA will ALWAYS be one-tailed and that will be upper-tailed only . Why? We know that in the formula, we are dividing the sum of squares between groups and within groups which would always yield a positive value and hence it will always be upper tailed . Find the level of significance Here level of significance is not provided; we will take the default \\alpha = 0.05 \\alpha = 0.05 Find the critical value We know that the two degrees of freedom - for the groups and within the groups are 2 and 27 respectively. So, df_1 = 2 df_1 = 2 and df_2 = 27 df_2 = 27 Looking into the F table (for ANOVA) at 0.05 significance level, we get the F_{critical} F_{critical} value as 3.35 3.35 (see image below) Find the test statistic To compute it manually, we will be using excel. The following screenshot shows how it is done. We know the formula is F = \\frac{VarianceBetweenGroups}{VarianceWithinGroups} = \\frac{\\frac{SSG}{df_{groups}}}{\\frac{SSE}{df_{error}}} F = \\frac{VarianceBetweenGroups}{VarianceWithinGroups} = \\frac{\\frac{SSG}{df_{groups}}}{\\frac{SSE}{df_{error}}}","title":"Solution approach"},{"location":"statistics/hypothesis_testing_04/#summary","text":"To summarize, we have seen two tests - the chi-square and the F test to test the variances in the population. We have also seen ANOVA - which is used to test the hypothesis when more than two groups of samples are picked from the population.","title":"Summary"}]}